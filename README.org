* concept
如果 把 框架 中 的 组件 比作 人体 的 各个 器官,
Request 和 Response 对象 是 血液, Item 则 是 代谢产物
* API
#+BEGIN_SRC python
req = Request(url[,
              callback,
              method='GET',
              headers,
              body,
              cookies,
              meta,
              encoding='utf-8',
              priority=0,
              dont_filter=False,
              errback])

import scrapy
request = scrapy.Request('http://books.toscrape.com/')
request2 = scrapy.Request('http://quotes.toscrape.com/', callback=self.parseItem)

在实际应用中, 我们几乎只调用Request的构造器创建对象,
但也可以根据需求访问Request对象的属性, 常用的有以下几个:

- url
- method
- headers
- body
- meta

这些属性和构造器参数相对应
#+END_SRC

#+BEGIN_SRC python
# response has 3 types: TextResponse, HtmlResponse, XmlResponse
#
# HtmlResponse
#
# property:
# - url, status, headers, body, text, encoding, request, meta, selector, xpath, css, urljoin

response.headers.get('Content-Type')
response.headers.getlist('Set-Cookie')

reponse.text = response.body.decode(response.encoding)

# resonse.meta 即response.request.meta
# 在构造Request对象时, 可将要传递给parse函数 的 信息 通过meta参数 传入;
# parse 函数处理响应时, 通过response.meta将信息取出
#+END_SRC
* workflow
实现 一个 Spider 子类 的 过程, 很像 是 完成 一系列 填空题:

Scrapy 框架 提出 以下 问题, 让 用户 在 Spider 子类 中 作答:
1. 爬虫 从 哪个 或 哪些 页面 开始 爬取?
2. 对于 一个 已下载 的 页面, 提取 其中 的 哪些 数据?
3. 爬取 完 当前 页面 后, 接下来 爬取 哪个 或 哪些 页面?

#+BEGIN_SRC python
class BooksSpider(scrapy.Spider):
    start_urls = ['http://books.toscrape.com/']

    def start_requests(self):
        for url in start_urls:
            yield scrapy.Request(url,
                                 callback=self.parse_book,
                                 headers={'User-Agent': 'Mozilla/5.0'},
                                 dont_filter=True)

    def parse_book(response):
        yield {}
        yield scrapy.Request(next_url, callback=self.parse_book)
#+END_SRC
* selector
#+BEGIN_SRC python
# create selector from text
from scrapy.selector import Selector
text = '''
<html>
  <body>
    <h1>Hello  World</h1>
    <h1>Hello Scrapy</h1>

    <b>Hello python</b>

    <ul>
      <li>C++</li>
      <li>Java</li>
      <li>Python</li>
    </ul>
  </body>
</html>
'''
selector = Selector(text=text)

# create selector from response
from scrapy.selector import Selector
from scrapy.http import HtmlResponse

body = '''
<html>
  <body>
    <h1>Hello  World</h1>
    <h1>Hello Scrapy</h1>

    <b>Hello python</b>

    <ul>
      <li>C++</li>
      <li>Java</li>
      <li>Python</li>
    </ul>
  </body>
</html>
'''

response = HtmlResponse(url='http://www.example.com', body=body, encoding='utf8')
selector = Selector(response=response)
response.selector # TextResponse property "selector"

response.xpath('.//h1/text()').extract() # call selector.xpath inside (defined in TextResponse)
response.css('li::text').extract()       # call selector.css inside   (defined in TextResponse)
#+END_SRC

#+BEGIN_SRC python
# selection
selector_list = selector.xpath('//h1') # select all <h1> in document
# output
#
# [<Selector xpath='.//h1' data='<h1>Hello  World</h1>'>,
#  <Selector xpath='.//h1' data='<h1>Hello Scrapy</h1>'>]

for sel in selector_list:
    print(sel.xpath('./text()'))
# output
#
# [<Selector xpath='./text()' data='Hello  World'>]
# [<Selector xpath='./text()' data='Hello Scrapy'>]

selector_list.xpath('./text()')
# output
#
# [<Selector xpath='./text()' data='Hello  World'>,
#  <Selector xpath='./text()' data='Hello Scrapy'>]

selector.xpath('.//ul').css('li').xpath('./text()')
# output
#
# [<Selector xpath='./text()' data='C++ '>,
#  <Selector xpath='./text()' data='Java'>,
#  <Selector xpath='./text()' data='Python'>]
#+END_SRC

#+BEGIN_SRC python
# extract data using extract

sl = selector.xpath('.//li')
sl[0].extract()
# output:   '<li>C++</li>'

sl = selector.xpath('.//li/text()')
sl[0].extract()
# output:   'C++'

sl = selector.xpath('.//li/text()')
sl.extract()
# output:   ['C++', 'Java', 'Python']

sl = selector.xpath('.//b')
sl.extract_first()
# output:   '<b>Hello Python</b>'
#+END_SRC

#+BEGIN_SRC python
# extract data using re
text = '''
<ul>
  <li>Python 学习手册 <b>价格: 99.00 元</b></li>
  <li>Python 核心编程 <b>价格: 88.00 元</b></li>
  <li>Python 基础教程 <b>价格: 80.00 元</b></li>
</ul>
'''
selector = Selector(text=text)
selector.xpath('.//li/b/text()')
selector.xpath('.//li/b/text()').extract()
# output:  ['价格: 99.00 元', '价格: 88.00 元', '价格: 80.00 元']
selector.xpath('.//li/b/text()').re('\d+\.\d+')
# output:  ['99.00', '88.00', '80.00']
#+END_SRC
* XPath
| expression  | description                        |
|-------------+------------------------------------|
| /           | root (not node)                    |
| .           | current node                       |
| ..          | parent node                        |
| ELEMENT     | All children nodes named ELEMENT   |
| //ELEMENT   | All descendant nodes named element |
| *           | All nodes                          |
| text()      | text node                          |
| @ATTR       | select node's attribute named ATTR |
| @*          | select node's all attributes       |
| [predicate] | specify node                       |

#+BEGIN_SRC python
from scrapy.selector import Selector
from scrapy.http import HtmlResponse

body = '''
<html>
  <head>
    <base href="http://example.com/" />
    <title>Example website</title>
  </head>

  <body>
    <div id="images">
      <a href="image1.html">Name: Image 1 <br /><img class="thumb" src="image1.jpg" /><strong>tail</strong></a>
      <a href="image2.html">Name: Image 2 <br /><img class="thumb" src="image2.jpg" /></a>
      <a href="image3.html">Name: Image 3 <br /><img src="image3.jpg" /></a>
      <a href="image4.html">Name: Image 4 <br /><img src="image4.jpg" /></a>
      <a href="image5.html">Name: Image 5 <br /><img src="image5.jpg" /></a>
    </div>
  </body>
</html>
'''

response = HtmlResponse(url='http://www.example.com', body=body, encoding='utf8')

# ipython
# run xpath_demo.py

## selector example
response.xpath('/html')
response.xpath('/html/head')
response.xpath('/html/body/div/a')

## selector //
response.xpath('//a')
response.xpath('/html/body//img')

## selector text()
response.xpath('//a/text()').extract()

## selector *
response.xpath('/html/*')
response.xpath('/html/body/div//*')
response.xpath('//div/*/img')

## attribute selector
response.xpath('//img/@src')
response.xpath('//@href')

## index is 1-based
response.xpath('//a[1]/img/@*')

## selector current
sel = response.xpath('//a')[0]
sel.xpath('//img')  # wrong, this will select at the root, so the images is not single
sel.xpath('.//img') # correct

## selector parent
response.xpath('//img/..')

## selector predicate
response.xpath('//a[3]')
response.xpath('//a[last()]')
response.xpath('//a[position()<=3]')
response.xpath('//div[@id]')
response.xpath('//div[@id="images"]')

response.xpath('//img[contains(@class, "thumb")]')

## xpath function
response.xpath('string(/html/body/div/a)').extract()
# return ['Name: Image 1 tail']
response.xpath('/html/body/div/a[1]//text()').extract()
# return ['Name: Image 1 ', 'tail']
#+END_SRC
